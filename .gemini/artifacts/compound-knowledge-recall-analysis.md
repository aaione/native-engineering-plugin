# CompoundçŸ¥è¯†å¤åˆ©æ²‰æ·€ä¸Skillå¬å›æœºåˆ¶æ·±åº¦åˆ†æ

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£æ·±å…¥åˆ†æ **Compound Engineering Plugin** ä¸­çš„çŸ¥è¯†å¤åˆ©(compound)æœºåˆ¶ï¼Œä¸Skillå¬å›æœºåˆ¶çš„å¯¹æ¯”ï¼Œä»¥åŠå¦‚ä½•å®ç°"åƒskillä¸€æ ·è‡ªåŠ¨å¬å›"çš„æ„¿æ™¯ã€‚

**æ ¸å¿ƒå‘ç°**:
1. âœ… **Compoundæœºåˆ¶å·²å­˜åœ¨** - `/workflow:compound` å‘½ä»¤å’Œ `compound-docs` skill
2. âš ï¸ **å¬å›æœºåˆ¶éƒ¨åˆ†ç¼ºå¤±** - çŸ¥è¯†æ²‰æ·€äº†ï¼Œä½†è‡ªåŠ¨å¬å›èƒ½åŠ›æœ‰é™
3. ğŸ¯ **æ”¹è¿›è·¯å¾„æ¸…æ™°** - éœ€è¦å»ºç«‹çŸ¥è¯†ç´¢å¼•å’Œä¸»åŠ¨å¬å›æœºåˆ¶

---

## 1ï¸âƒ£ å½“å‰CompoundçŸ¥è¯†æ²‰æ·€æœºåˆ¶åˆ†æ

### 1.1 æ ¸å¿ƒå·¥ä½œæµç¨‹

```mermaid
flowchart TB
    SOLVE[é—®é¢˜å·²è§£å†³] --> TRIGGER{è§¦å‘compound}
    TRIGGER -->|è‡ªåŠ¨| AUTO[æ£€æµ‹åˆ°: that worked, it's fixedç­‰]
    TRIGGER -->|æ‰‹åŠ¨| MANUAL[/workflow:compound]
    
    AUTO --> PARALLEL
    MANUAL --> PARALLEL
    
    subgraph PARALLEL[6ä¸ªå¹¶è¡Œå­ä»£ç†]
        CA[Context Analyzer<br/>ä¸Šä¸‹æ–‡åˆ†æ]
        SE[Solution Extractor<br/>æ–¹æ¡ˆæå–]
        RDF[Related Docs Finder<br/>å…³è”æ–‡æ¡£]
        PS[Prevention Strategist<br/>é¢„é˜²ç­–ç•¥]
        CC[Category Classifier<br/>åˆ†ç±»å™¨]
        DW[Documentation Writer<br/>æ–‡æ¡£ç¼–å†™]
    end
    
    PARALLEL --> VALIDATE[YAML SchemaéªŒè¯]
    VALIDATE --> OUTPUT[docs/solutions/<br/>category/slug.md]
    
    OUTPUT --> DECISION{å†³ç­–èœå•}
    DECISION -->|1| CONTINUE[ç»§ç»­å·¥ä½œæµ]
    DECISION -->|2| CRITICAL[æ·»åŠ åˆ°å¿…è¯»æ¨¡å¼<br/>cora-critical-patterns.md]
    DECISION -->|3| LINK[å…³è”ç›¸å…³é—®é¢˜]
    DECISION -->|4| EXISTING_SKILL[æ·»åŠ åˆ°ç°æœ‰Skill]
    DECISION -->|5| NEW_SKILL[åˆ›å»ºæ–°Skill]
    
    style OUTPUT fill:#e8f5e9
    style CRITICAL fill:#fff3e0
    style NEW_SKILL fill:#e1f5fe
```

### 1.2 çŸ¥è¯†æ²‰æ·€çš„ä¸‰ä¸ªå±‚æ¬¡

| å±‚æ¬¡ | ä½ç½® | ä½œç”¨ | è‡ªåŠ¨å¬å›èƒ½åŠ› |
|------|------|------|-------------|
| **L1: è§£å†³æ–¹æ¡ˆæ–‡æ¡£** | `docs/solutions/category/*.md` | é—®é¢˜ç—‡çŠ¶ã€æ ¹å› ã€è§£å†³æ–¹æ¡ˆ | âš ï¸ è¢«åŠ¨æŸ¥æ‰¾ |
| **L2: å¿…è¯»æ¨¡å¼** | `docs/solutions/patterns/cora-critical-patterns.md` | æç‚¼ä¸ºâŒ/âœ…å¯¹æ¯”æ¨¡å¼ | âœ… æ‰€æœ‰ä»£ç†ç”Ÿæˆå‰æŸ¥çœ‹ |
| **L3: SkillåŒ–** | `plugins/compound-engineering/skills/[skill-name]/` | å®Œæ•´æŠ€èƒ½åŒ…(SKILL.md + èµ„æº) | âœ… å¼ºå¬å› |

**å‘ç°**: å­˜åœ¨ä¸‰çº§çŸ¥è¯†æ²‰æ·€è·¯å¾„ï¼Œä½†**åªæœ‰L2å’ŒL3æœ‰ä¸»åŠ¨å¬å›**ã€‚

---

## 2ï¸âƒ£ Skillå¬å›æœºåˆ¶æ·±åº¦è§£æ„

### 2.1 Skillçš„è‡ªåŠ¨å‘ç°ä¸å¬å›æµç¨‹

```mermaid
sequenceDiagram
    participant User
    participant Claude
    participant SkillSystem
    participant L1 as Level 1: Metadata
    participant L2 as Level 2: SKILL.md
    participant L3 as Level 3: Resources
    
    User->>Claude: å‘èµ·ä»»åŠ¡è¯·æ±‚
    Claude->>SkillSystem: åˆ†æä»»åŠ¡éœ€æ±‚
    SkillSystem->>L1: æ‰«ææ‰€æœ‰skillçš„name+description
    Note over L1: å§‹ç»ˆåœ¨context<br/>(~100 words/skill)
    L1->>SkillSystem: è¿”å›åŒ¹é…çš„skillå€™é€‰
    SkillSystem->>L2: åŠ è½½åŒ¹é…skillçš„SKILL.md
    Note over L2: è§¦å‘æ—¶åŠ è½½<br/>(<5k words)
    L2->>SkillSystem: è¿”å›è¯¦ç»†æŒ‡ä»¤
    SkillSystem->>L3: æŒ‰éœ€åŠ è½½references/scripts/assets
    Note over L3: è¿è¡Œæ—¶æŒ‰éœ€åŠ è½½<br/>(Unlimited)
    SkillSystem->>Claude: ä½¿ç”¨skillæ‰§è¡Œä»»åŠ¡
    Claude->>User: è¿”å›ç»“æœ
```

### 2.2 Skillå¬å›çš„å…³é”®è¦ç´ 

#### âœ… **å·²å®ç°çš„å¬å›æœºåˆ¶**

1. **Progressive Disclosure (æ¸è¿›å¼æŠ«éœ²)**
   ```yaml
   Level 1: name + description  # å§‹ç»ˆåœ¨context (æ‰€æœ‰skills)
   Level 2: SKILL.md body       # è§¦å‘æ—¶åŠ è½½ (<5k words)
   Level 3: Bundled resources   # æŒ‰éœ€åŠ è½½ (Unlimited)
   ```

2. **å¤šæºå‘ç°è·¯å¾„** (æ¥è‡ª`deepen-plan.md`çš„è®¾è®¡)
   ```bash
   # 1. é¡¹ç›®æœ¬åœ°skills (æœ€é«˜ä¼˜å…ˆçº§)
   .claude/skills/
   
   # 2. ç”¨æˆ·å…¨å±€skills
   ~/.claude/skills/
   
   # 3. compound-engineering plugin skills
   ~/.claude/plugins/cache/*/compound-engineering/*/skills/
   
   # 4. æ‰€æœ‰å·²å®‰è£…æ’ä»¶çš„skills
   find ~/.claude/plugins/cache -type d -name "skills"
   ```

3. **è§¦å‘æœºåˆ¶**
   - **æè¿°åŒ¹é…**: skillçš„descriptionåŒ…å«ä»»åŠ¡å…³é”®è¯
   - **æ˜¾å¼è°ƒç”¨**: å‘½ä»¤æˆ–ä»£ç†ç›´æ¥è·¯ç”±åˆ°skill (å¦‚ `/workflow:compound` â†’ `compound-docs`)
   - **åŠ¨æ€åŒ¹é…**: è¿è¡Œæ—¶æ‰«ææ‰€æœ‰skillså¹¶åŒ¹é… (è§`deepen-plan.md` Step 2)

---

## 3ï¸âƒ£ CompoundçŸ¥è¯† vs Skillå¬å› - æ ¸å¿ƒå·®å¼‚

### 3.1 å¯¹æ¯”è¡¨

| ç»´åº¦ | CompoundçŸ¥è¯† (docs/solutions/) | Skillæœºåˆ¶ |
|------|-------------------------------|----------|
| **æ ¼å¼** | Markdownæ–‡æ¡£ (YAML frontmatter) | SKILL.md + èµ„æºåŒ… |
| **ç»„ç»‡** | æŒ‰é—®é¢˜ç±»å‹åˆ†ç±» (9ä¸ªcategoryç›®å½•) | æŒ‰èƒ½åŠ›åŸŸåˆ†ç±» (14ä¸ªskillç›®å½•) |
| **å…ƒæ•°æ®** | ä¸°å¯Œ (problem_type, component, symptoms, root_causeç­‰) | ç®€æ´ (name, description) |
| **è‡ªåŠ¨å‘ç°** | âŒ æ—  - éœ€è¦æ‰‹åŠ¨æœç´¢æˆ–è¢«å¼•ç”¨ | âœ… æœ‰ - name/descriptionå§‹ç»ˆåœ¨context |
| **ä¸»åŠ¨å¬å›** | âŒ ä»…è¢«åŠ¨æŸ¥æ‰¾ (`grep`, `find`) | âœ… ä¸»åŠ¨åŒ¹é…ä»»åŠ¡ |
| **è§¦å‘æ—¶æœº** | éœ€äººå·¥è®°å¿†/æœç´¢,æˆ–è¢«å…¶ä»–æµç¨‹å¼•ç”¨ | ä»»åŠ¡å…³é”®è¯è‡ªåŠ¨è§¦å‘ |
| **å¯æ‰§è¡Œæ€§** | æ–‡æ¡£æ€§ - éœ€äººå·¥åº”ç”¨ | å¯æ‰§è¡Œ - SKILL.mdåŒ…å«æŒ‡ä»¤,scriptså¯ç›´æ¥è¿è¡Œ |
| **å¤ç”¨åœºæ™¯** | è§£å†³ç›¸åŒ/ç±»ä¼¼é—®é¢˜æ—¶å‚è€ƒ | æ‰§è¡Œç›¸åŒç±»å‹ä»»åŠ¡æ—¶è‡ªåŠ¨åº”ç”¨ |

### 3.2 å…³é”®æ´å¯Ÿ

**CompoundçŸ¥è¯†çš„æœ¬è´¨**: 
- ğŸ“š **è¢«åŠ¨çŸ¥è¯†åº“** - é«˜è´¨é‡æ–‡æ¡£,ä½†éœ€è¦"è®°å¾—å»æŸ¥"
- ğŸ¯ **ç»“æ„åŒ–ç»éªŒ** - YAML schemaä¿è¯ä¸€è‡´æ€§å’Œå¯ç´¢å¼•æ€§

**Skillçš„æœ¬è´¨**:
- ğŸ¤– **ä¸»åŠ¨ä»£ç†æ‰©å±•** - AIä¸»åŠ¨å‘ç°å¹¶ä½¿ç”¨
- ğŸ”§ **å¯æ‰§è¡Œå·¥å…·åŒ…** - ä¸åªæ˜¯æ–‡æ¡£,è¿˜åŒ…å«è„šæœ¬å’Œæ¨¡æ¿

**é—®é¢˜æ‰€åœ¨**:
> Compoundæœºåˆ¶æ²‰æ·€äº†é«˜è´¨é‡çŸ¥è¯†,ä½†**ç¼ºå°‘åƒSkillé‚£æ ·çš„è‡ªåŠ¨å‘ç°å’Œå¬å›å±‚**ã€‚

---

## 4ï¸âƒ£ å®ç°"åƒSkillä¸€æ ·å¬å›" - æŠ€æœ¯è·¯å¾„

### 4.1 æ–¹æ¡ˆA: å°†CompoundçŸ¥è¯†SkillåŒ– (æ¨è â­)

#### è®¾è®¡æ€è·¯

åˆ›å»ºä¸€ä¸ª**å…ƒSkill**: `compound-knowledge-retriever`

```
skills/compound-knowledge-retriever/
â”œâ”€â”€ SKILL.md                    # æ ¸å¿ƒæ£€ç´¢é€»è¾‘
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ index_solutions.py      # ç´¢å¼•æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ semantic_search.py      # è¯­ä¹‰æœç´¢
â”‚   â””â”€â”€ retrieve_relevant.py    # ç›¸å…³æ–‡æ¡£å¬å›
â”œâ”€â”€ references/
â”‚   â”œâ”€â”€ solution_index.json     # è‡ªåŠ¨ç”Ÿæˆçš„ç´¢å¼•
â”‚   â””â”€â”€ category_taxonomy.yaml  # åˆ†ç±»ä½“ç³»
â””â”€â”€ assets/
    â””â”€â”€ search_prompt_template.md
```

#### SKILL.md æ ¸å¿ƒé€»è¾‘

```markdown
---
name: compound-knowledge-retriever
description: Automatically retrieve relevant documented solutions from docs/solutions/ when encountering similar problems, patterns, or implementation tasks. Prevents repeating past mistakes by surfacing institutional knowledge.
allowed-tools:
  - Read
  - Bash
preconditions:
  - docs/solutions/ directory exists with categorized solution files
---

# Compound Knowledge Retriever

## Purpose
Proactively search and surface relevant past solutions when:
- Encountering errors or bugs
- Planning implementations that might have pitfalls
- Reviewing code for common anti-patterns

## Automatic Triggering

This skill should activate when Claude detects:
- Error messages or stack traces
- Planning tasks involving [technologies in past solutions]
- Code review requests
- Architecture design discussions

## Retrieval Process

### Step 1: Index Check
- Load `references/solution_index.json` (auto-generated index)
- If index is stale (>24h), rebuild with `scripts/index_solutions.py`

### Step 2: Query Construction
Extract from current context:
- Technologies mentioned (e.g., Rails, React, PostgreSQL)
- Problem symptoms (error messages, performance issues)
- Components involved (models, controllers, APIs)

### Step 3: Search Strategy
Run parallel searches:
1. **Exact match**: Error message in symptoms field
2. **Tag match**: Technologies/patterns in tags field
3. **Category match**: problem_type aligned with current task
4. **Semantic search**: `scripts/semantic_search.py` for similar issues

### Step 4: Relevance Filtering
For each candidate solution:
- Check YAML frontmatter tags vs. current task
- Score by similarity (0-100)
- Return top 3-5 most relevant

### Step 5: Present Findings
Format as:
```
ğŸ“š Relevant Past Solutions Found:

1. [Title from YAML] (Similarity: 95%)
   - Root Cause: [root_cause field]
   - Quick Fix: [one-line summary of solution]
   - Full Doc: docs/solutions/[path]
   
2. [...]
```

### Step 6: Apply or Reference
- If highly relevant (>90%), proactively suggest applying the solution
- If moderately relevant (60-89%), mention as context
- Always link to full documentation for details
```

#### å®ç°ç»†èŠ‚

**ç´¢å¼•æ„å»ºè„šæœ¬** (`scripts/index_solutions.py`):
```python
#!/usr/bin/env python3
import os
import yaml
import json
from pathlib import Path

def build_index(solutions_dir="docs/solutions"):
    index = {"solutions": [], "metadata": {}}
    
    for md_file in Path(solutions_dir).rglob("*.md"):
        with open(md_file, 'r') as f:
            content = f.read()
            # Extract YAML frontmatter
            if content.startswith('---'):
                yaml_end = content.find('---', 3)
                frontmatter = yaml.safe_load(content[3:yaml_end])
                
                index["solutions"].append({
                    "path": str(md_file),
                    "category": md_file.parent.name,
                    "metadata": frontmatter,
                    "search_text": " ".join([
                        frontmatter.get("module", ""),
                        frontmatter.get("problem_type", ""),
                        " ".join(frontmatter.get("tags", [])),
                        " ".join(frontmatter.get("symptoms", []))
                    ]).lower()
                })
    
    index["metadata"]["total_solutions"] = len(index["solutions"])
    index["metadata"]["last_updated"] = str(datetime.now())
    
    with open("skills/compound-knowledge-retriever/references/solution_index.json", 'w') as f:
        json.dump(index, f, indent=2)
    
    print(f"âœ“ Indexed {len(index['solutions'])} solutions")

if __name__ == "__main__":
    build_index()
```

#### é›†æˆåˆ°ç°æœ‰å·¥ä½œæµ

**åœ¨å…³é”®å‘½ä»¤ä¸­ä¸»åŠ¨è°ƒç”¨**:

1. **`/workflow:plan`** - è§„åˆ’å‰æŸ¥æ‰¾ç›¸å…³è§£å†³æ–¹æ¡ˆ,é¿å…å·²çŸ¥é™·é˜±
   ```markdown
   # åœ¨ spec-flow-analyzer ä¹‹å‰
   - è°ƒç”¨ compound-knowledge-retriever
   - æœç´¢ä¸åŠŸèƒ½ç›¸å…³çš„past solutions
   - å°†findingsæ³¨å…¥åˆ°plançš„"Considerations"éƒ¨åˆ†
   ```

2. **`/deepen-plan`** - Step 3å·²æœ‰learningså‘ç°é€»è¾‘,å¢å¼ºä¸ºä½¿ç”¨æ­¤skill
   ```markdown
   # æ›¿æ¢å½“å‰çš„find + headé€»è¾‘
   - ä½¿ç”¨ compound-knowledge-retriever skill
   - è‡ªåŠ¨è¿‡æ»¤å’Œç›¸å…³æ€§è¯„åˆ†
   - å¹¶è¡Œspawn sub-agents for top matches
   ```

3. **`/workflow:work`** - å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯æ—¶è‡ªåŠ¨æŸ¥æ‰¾
   ```markdown
   # Phase 2æ‰§è¡Œä¸­,æ£€æµ‹åˆ°é”™è¯¯æ—¶
   - è‡ªåŠ¨è§¦å‘ compound-knowledge-retriever
   - æœç´¢error message in symptoms
   - å±•ç¤ºpast solutions before debugging
   ```

4. **`/workflow:review`** - å®¡æŸ¥æ—¶æ£€æŸ¥æ˜¯å¦é‡å¤å·²çŸ¥é—®é¢˜
   ```markdown
   # åœ¨14ä¸ªreview agentsä¹‹å
   - è¿è¡Œ compound-knowledge-retriever
   - æ£€æŸ¥ä»£ç å˜æ›´æ˜¯å¦è§¦å‘å·²çŸ¥anti-patterns
   - æ ‡è®°ä¸ºP2/P3 todos if applicable
   ```

---

### 4.2 æ–¹æ¡ˆB: å¢å¼ºdeepen-plançš„Learningå¬å› (å¿«é€Ÿæ–¹æ¡ˆ)

**å½“å‰çŠ¶æ€** (deepen-plan.md, lines 145-267):
- âœ… å·²æœ‰learningså‘ç°é€»è¾‘
- âš ï¸ åŸºäºç®€å•çš„file scan + frontmatter filtering
- âš ï¸ éœ€è¦æ‰‹åŠ¨è°ƒç”¨ `/deepen-plan`

**å¢å¼ºè·¯å¾„**:

1. **è‡ªåŠ¨åŒ–ç´¢å¼•**
   - åœ¨ `compound-docs` skillçš„Step 6 (Create Documentation)å
   - è‡ªåŠ¨è¿è¡Œç´¢å¼•æ›´æ–°è„šæœ¬
   - ç»´æŠ¤ `.claude/artifacts/solutions-index.json`

2. **ä¸»åŠ¨å¬å›è§¦å‘**
   - ä¿®æ”¹ `/workflow:plan` çš„ `spec-flow-analyzer`
   - åœ¨ç”Ÿæˆplanå‰è‡ªåŠ¨æœç´¢relevant learnings
   - æ³¨å…¥åˆ°plançš„initial research section

3. **ä¼˜åŒ–è¿‡æ»¤é€»è¾‘**
   ```python
   # å½“å‰: ç®€å•çš„tag/categoryå­—ç¬¦ä¸²åŒ¹é…
   # æ”¹è¿›: åŠ å…¥ç›¸ä¼¼åº¦è¯„åˆ†
   def calculate_relevance(learning_metadata, plan_context):
       score = 0
       # Tag overlap (0-40åˆ†)
       common_tags = set(learning_metadata['tags']) & set(plan_context['technologies'])
       score += len(common_tags) * 10
       
       # Category match (0-30åˆ†)
       if learning_metadata['category'] in plan_context['domains']:
           score += 30
       
       # Symptom keyword match (0-30åˆ†)
       for symptom in learning_metadata['symptoms']:
           if any(kw in symptom.lower() for kw in plan_context['keywords']):
               score += 10
       
       return min(score, 100)
   ```

---

### 4.3 æ–¹æ¡ˆC: åˆ›å»ºä¸“é—¨çš„Knowledge Agent

**è®¾è®¡**: ä¸€ä¸ªæ–°çš„research agent: `institutional-knowledge-researcher`

```
agents/research/institutional-knowledge-researcher.md
```

**æ ¸å¿ƒèŒè´£**:
- åœ¨planningå’Œreviewé˜¶æ®µè¢«æ˜¾å¼è°ƒç”¨
- æœç´¢ `docs/solutions/` å’Œ critical patterns
- è¿”å›ç»“æ„åŒ–çš„"lessons learned"

**è°ƒç”¨ç‚¹**:
- `/workflow:plan` - ä½œä¸ºç¬¬4ä¸ªå¹¶è¡Œresearch agent
- `/workflow:review` - ä½œä¸ºç¬¬15ä¸ªreview agent
- `/deepen-plan` - åœ¨Step 5ä¸­æ˜¾å¼è°ƒç”¨

**ä¼˜åŠ¿**:
- æ— éœ€ä¿®æ”¹ç°æœ‰skillç»“æ„
- å¯ä»¥ä¸å…¶ä»–agentså¹¶è¡Œè¿è¡Œ
- æ˜ç¡®çš„èŒè´£è¾¹ç•Œ

**åŠ£åŠ¿**:
- ä¸æ˜¯"è‡ªåŠ¨å¬å›",ä»éœ€è¦workflowæ˜¾å¼è°ƒç”¨
- éœ€è¦åœ¨å¤šä¸ªå‘½ä»¤ä¸­é‡å¤é›†æˆ

---

## 5ï¸âƒ£ æ¨èå®æ–½è·¯çº¿å›¾

### Phase 1: å¿«é€Ÿå¢å¼º (1-2å¤©)

**ç›®æ ‡**: è®©ç°æœ‰çš„compoundçŸ¥è¯†åœ¨å…³é”®ç¯èŠ‚è¢«ä¸»åŠ¨å¬å›

1. âœ… **åˆ›å»ºç´¢å¼•è„šæœ¬**
   - `scripts/index_solutions.py` - æ‰«æ `docs/solutions/` ç”ŸæˆJSONç´¢å¼•
   - åœ¨ `compound-docs` skillçš„Step 7åè‡ªåŠ¨è¿è¡Œ

2. âœ… **å¢å¼º `/deepen-plan`**
   - æ›¿æ¢Step 3çš„æ‰‹åŠ¨file scanä¸ºç´¢å¼•æŸ¥è¯¢
   - åŠ å…¥ç›¸ä¼¼åº¦è¯„åˆ†é€»è¾‘
   - ä¼˜å…ˆå¬å›é«˜åˆ†learnings

3. âœ… **é›†æˆåˆ° `/workflow:plan`**
   - åœ¨ `spec-flow-analyzer` ä¹‹å‰
   - è‡ªåŠ¨æœç´¢relevant solutions
   - æ³¨å…¥åˆ°plançš„"Known Pitfalls"éƒ¨åˆ†

### Phase 2: SkillåŒ– (3-5å¤©)

**ç›®æ ‡**: åˆ›å»ºå®Œæ•´çš„ `compound-knowledge-retriever` skill

1. âœ… **åˆ›å»ºSkillç»“æ„**
   - SKILL.md with clear triggering logic
   - scripts/ for indexing and search
   - references/ for generated index
   - ä½¿ç”¨ `skill-creator` skillè¾…åŠ©åˆ›å»º

2. âœ… **å®ç°è¯­ä¹‰æœç´¢** (å¯é€‰,é«˜çº§)
   - ä½¿ç”¨è½»é‡çº§embedding (å¦‚sentence-transformers)
   - æˆ–åŸºäºå…³é”®è¯TF-IDF
   - æå‡å¬å›å‡†ç¡®ç‡

3. âœ… **é›†æˆåˆ°æ‰€æœ‰æ ¸å¿ƒworkflows**
   - `/workflow:plan` - pre-planning
   - `/workflow:work` - error detection
   - `/workflow:review` - anti-pattern check
   - `/deepen-plan` - learnings discovery

### Phase 3: æ™ºèƒ½åŒ– (é•¿æœŸä¼˜åŒ–)

**ç›®æ ‡**: ä¸»åŠ¨å­¦ä¹ å’Œæ¨è

1. âœ… **è‡ªåŠ¨æ¨¡å¼æå–**
   - å½“ç›¸åŒroot_causeå‡ºç°3+æ¬¡
   - è‡ªåŠ¨æç¤ºå‡çº§ä¸ºcritical pattern (L2)
   - æˆ–å»ºè®®åˆ›å»ºæ–°skill (L3)

2. âœ… **ä½¿ç”¨ç»Ÿè®¡**
   - è¿½è¸ªæ¯ä¸ªsolutionè¢«å¬å›çš„æ¬¡æ•°
   - é«˜é¢‘solutionsè‡ªåŠ¨ææƒ
   - è¿‡æ—¶solutionsæ ‡è®°deprecation

3. âœ… **è·¨é¡¹ç›®çŸ¥è¯†å…±äº«** (å¯é€‰)
   - Export/import solution packages
   - ç¤¾åŒºknowledge marketplace
   - Privacy-aware sharing (è„±æ•)

---

## 6ï¸âƒ£ å®æ–½ç¤ºä¾‹

### ç¤ºä¾‹1: è§„åˆ’é˜¶æ®µè‡ªåŠ¨å¬å›

**åœºæ™¯**: ç”¨æˆ·è¿è¡Œ `/workflow:plan` åˆ›å»º"Add Redis caching to API"

**å½“å‰è¡Œä¸º**:
```
1. repo-research-analyst: åˆ†æä»“åº“
2. best-practices-researcher: æœç´¢Redisæœ€ä½³å®è·µ
3. framework-docs-researcher: æŸ¥è¯¢Rails cacheæ–‡æ¡£
4. spec-flow-analyzer: ç”Ÿæˆplan
â†’ è¾“å‡º: plans/add-redis-caching.md
```

**å¢å¼ºåè¡Œä¸º**:
```
0. compound-knowledge-retriever: æœç´¢docs/solutions/
   â†’ å‘ç°: docs/solutions/performance-issues/redis-cache-stampede.md
   â†’ å‘ç°: docs/solutions/configuration-fixes/redis-connection-pool.md
   â†’ Relevance: 95%, 88%

1. repo-research-analyst: åˆ†æä»“åº“
2. best-practices-researcher: æœç´¢Redisæœ€ä½³å®è·µ
3. framework-docs-researcher: æŸ¥è¯¢Rails cacheæ–‡æ¡£

4. spec-flow-analyzer: ç”Ÿæˆplan
   â†’ è‡ªåŠ¨æ³¨å…¥section:
   
   ## Known Pitfalls (from Past Solutions)
   
   âš ï¸ Cache Stampede Risk (95% relevance)
   - Past Issue: docs/solutions/performance-issues/redis-cache-stampede.md
   - Mitigation: Use `race_condition_ttl` in Rails.cache.fetch
   
   âš ï¸ Connection Pool Exhaustion (88% relevance)
   - Past Issue: docs/solutions/configuration-fixes/redis-connection-pool.md
   - Mitigation: Configure pool size based on worker count
   
â†’ è¾“å‡º: plans/add-redis-caching.md (with embedded learnings)
```

**æ•ˆæœ**:
- âœ… é¿å…é‡å¤è¿‡å»çš„é”™è¯¯
- âœ… Planè´¨é‡æå‡ - åŒ…å«proven mitigations
- âœ… èŠ‚çœdebuggingæ—¶é—´

---

### ç¤ºä¾‹2: å¼€å‘é˜¶æ®µé”™è¯¯å¬å›

**åœºæ™¯**: `/workflow:work` æ‰§è¡Œä¸­é‡åˆ°é”™è¯¯

```ruby
# User is implementing caching
Rails.cache.fetch(key) do
  expensive_query
end

# Error appears:
Redis::TimeoutError: Connection timeout
```

**å½“å‰è¡Œä¸º**:
```
Userçœ‹åˆ°error â†’ æ‰‹åŠ¨debugging â†’ Googleæœç´¢ â†’ è¯•é”™
â†’ 20åˆ†é’Ÿåè§£å†³
```

**å¢å¼ºåè¡Œä¸º**:
```
1. compound-knowledge-retrieverè‡ªåŠ¨è§¦å‘
2. æœç´¢error message: "Redis::TimeoutError"
3. å¬å›: docs/solutions/configuration-fixes/redis-connection-pool.md

ğŸ“š Relevant Past Solution Found:

**Redis Connection Pool Timeout** (Exact Match: 100%)
- Root Cause: Default pool size (5) too small for worker count
- Quick Fix: Set REDIS_POOL_SIZE env var to match worker threads
- Tested Solution:
  ```ruby
  # config/initializers/redis.rb
  Redis.new(
    url: ENV['REDIS_URL'],
    pool_size: ENV.fetch('REDIS_POOL_SIZE', 20).to_i
  )
  ```
- Full Documentation: docs/solutions/configuration-fixes/redis-connection-pool.md

Apply this solution? [Y/n]

â†’ User: Y
â†’ Claudeè‡ªåŠ¨åº”ç”¨fix
â†’ 2åˆ†é’Ÿè§£å†³ (vs 20åˆ†é’Ÿ)
```

**æ•ˆæœ**:
- âœ… 10xæ—¶é—´èŠ‚çœ
- âœ… ä¸€è‡´æ€§ - ä½¿ç”¨proven solution
- âœ… Knowledgeå¤åˆ©ä½“ç° - ç¬¬ä¸€æ¬¡30åˆ†é’Ÿ,è®°å½•5åˆ†é’Ÿ,ä¹‹åæ¯æ¬¡2åˆ†é’Ÿ

---

## 7ï¸âƒ£ æŠ€æœ¯å®ç°ç»†èŠ‚

### 7.1 ç´¢å¼•Schemaè®¾è®¡

```json
{
  "version": "1.0",
  "last_updated": "2026-01-17T14:00:00Z",
  "total_solutions": 15,
  "solutions": [
    {
      "id": "perf-001",
      "path": "docs/solutions/performance-issues/redis-cache-stampede.md",
      "category": "performance_issue",
      "metadata": {
        "module": "API",
        "date": "2025-11-10",
        "problem_type": "performance_issue",
        "component": "database",
        "symptoms": [
          "Sudden spike in database queries",
          "Cache miss storm"
        ],
        "root_cause": "missing_race_condition_handling",
        "resolution_type": "code_fix",
        "severity": "high",
        "tags": ["redis", "caching", "race-condition", "rails"]
      },
      "search_vectors": {
        "symptom_keywords": ["spike", "database", "queries", "cache", "miss", "storm"],
        "technology_keywords": ["redis", "rails", "cache"],
        "error_signatures": []
      },
      "usage_stats": {
        "times_retrieved": 5,
        "last_retrieved": "2026-01-15T10:30:00Z",
        "applied_count": 3
      }
    }
  ],
  "indices": {
    "by_category": {
      "performance_issue": ["perf-001", "perf-002"],
      "database_issue": ["db-001"]
    },
    "by_technology": {
      "redis": ["perf-001", "config-001"],
      "rails": ["perf-001", "db-001"],
      "postgres": ["db-001"]
    },
    "by_error_signature": {
      "Redis::TimeoutError": ["config-001"],
      "PG::QueryCanceled": ["db-002"]
    }
  }
}
```

### 7.2 æ£€ç´¢ç®—æ³•ä¼ªä»£ç 

```python
def retrieve_relevant_solutions(task_context, index, top_k=5):
    """
    task_context = {
        'technologies': ['redis', 'rails'],
        'error_message': 'Redis::TimeoutError: Connection timeout',
        'task_type': 'implementation',  # or 'debugging', 'review'
        'keywords': ['caching', 'api', 'performance']
    }
    """
    candidates = []
    
    # Pass 1: Exact error signature match (highest priority)
    error_sig = extract_error_signature(task_context.get('error_message', ''))
    if error_sig in index['indices']['by_error_signature']:
        for solution_id in index['indices']['by_error_signature'][error_sig]:
            candidates.append({
                'id': solution_id,
                'score': 100,  # Exact match
                'reason': 'Exact error signature match'
            })
    
    # Pass 2: Technology tag intersection
    for tech in task_context.get('technologies', []):
        if tech in index['indices']['by_technology']:
            for solution_id in index['indices']['by_technology'][tech]:
                if solution_id not in [c['id'] for c in candidates]:
                    solution = get_solution_by_id(index, solution_id)
                    score = calculate_tag_overlap_score(
                        solution['metadata']['tags'],
                        task_context['keywords']
                    )
                    if score > 50:  # Threshold
                        candidates.append({
                            'id': solution_id,
                            'score': score,
                            'reason': f'Technology match: {tech}'
                        })
    
    # Pass 3: Keyword similarity in symptoms
    for solution in index['solutions']:
        if solution['id'] not in [c['id'] for c in candidates]:
            score = calculate_keyword_similarity(
                solution['search_vectors']['symptom_keywords'],
                task_context['keywords']
            )
            if score > 40:
                candidates.append({
                    'id': solution['id'],
                    'score': score,
                    'reason': 'Symptom keyword similarity'
                })
    
    # Sort by score (descending) and usage stats (boost frequently used)
    candidates = sorted(candidates, key=lambda c: (
        c['score'] + get_usage_boost(index, c['id'])
    ), reverse=True)
    
    return candidates[:top_k]

def get_usage_boost(index, solution_id):
    """Boost score based on past usage"""
    solution = get_solution_by_id(index, solution_id)
    times_retrieved = solution['usage_stats']['times_retrieved']
    applied_count = solution['usage_stats']['applied_count']
    
    # More frequently applied = higher boost (max +15)
    return min((applied_count * 3), 15)
```

---

## 8ï¸âƒ£ æˆåŠŸæŒ‡æ ‡

### å®šé‡æŒ‡æ ‡

| æŒ‡æ ‡ | åŸºçº¿ | ç›®æ ‡ (3ä¸ªæœˆå) | æµ‹é‡æ–¹æ³• |
|------|------|--------------|----------|
| **Knowledgeå¬å›ç‡** | 0% (æ‰‹åŠ¨æŸ¥æ‰¾) | 80% | åœ¨plan/work/reviewä¸­è‡ªåŠ¨å¬å›relevant solutionsçš„æˆåŠŸç‡ |
| **é‡å¤é—®é¢˜è§£å†³æ—¶é—´** | é¦–æ¬¡: 30min<br/>é‡å¤: 20min | é¦–æ¬¡: 30min<br/>é‡å¤: 5min | å¯¹æ¯”åŒä¸€root_causeçš„é¦–æ¬¡vsé‡å¤è§£å†³æ—¶é—´ |
| **Solutionsè¢«åº”ç”¨ç‡** | N/A | 60% | è¢«å¬å›çš„solutionsä¸­,å®é™…è¢«é‡‡çº³çš„æ¯”ä¾‹ |
| **Knowledgeåº“å¢é•¿ç‡** | ~2/week | 5/week | æ–°å¢`docs/solutions/` files per week |

### å®šæ€§æŒ‡æ ‡

- âœ… **ä¸»åŠ¨æ€§**: AIèƒ½åœ¨ç”¨æˆ·è¯´"æˆ‘é‡åˆ°Xé”™è¯¯"ä¹‹å‰,å°±æç¤º"æˆ‘ä»¬ä¹‹å‰é‡åˆ°è¿‡ç±»ä¼¼é—®é¢˜"
- âœ… **å‡†ç¡®æ€§**: å¬å›çš„solutionsé«˜åº¦ç›¸å…³(>80% relevance)
- âœ… **å¯å‘ç°æ€§**: ç”¨æˆ·æ— éœ€è®°ä½"å»æŸ¥docs/solutions/",ç³»ç»Ÿä¸»åŠ¨æ¨é€
- âœ… **å¤åˆ©æ•ˆåº”**: æ¯æ¬¡è®°å½•çš„solution,åœ¨3æ¬¡ä»¥ä¸Šä»»åŠ¡ä¸­è¢«å¤ç”¨

---

## 9ï¸âƒ£ é£é™©ä¸ç¼“è§£

### é£é™©1: ç´¢å¼•ç»´æŠ¤æˆæœ¬

**é£é™©**: solutionæ–‡ä»¶å¢å¤šå,ç´¢å¼•æ„å»ºå˜æ…¢

**ç¼“è§£**:
- å¢é‡ç´¢å¼•æ›´æ–°(åªé‡æ–°ç´¢å¼•changed files)
- å®šæœŸæ¸…ç†è¿‡æ—¶solutions (6ä¸ªæœˆæœªè¢«å¬å› â†’ æ ‡è®°deprecation)
- ç´¢å¼•å¼‚æ­¥æ„å»º,ä¸é˜»å¡ä¸»å·¥ä½œæµ

### é£é™©2: å¬å›å™ªéŸ³ (irrelevant suggestions)

**é£é™©**: é”™è¯¯å¬å›ä¸ç›¸å…³çš„solutions,å¹²æ‰°ç”¨æˆ·

**ç¼“è§£**:
- è®¾ç½®relevance threshold (åªæ˜¾ç¤º>60%çš„results)
- "Not helpful"åé¦ˆæœºåˆ¶,é™ä½è¯¯å¬å›solutionçš„æƒé‡
- åˆ†å±‚å±•ç¤º: Exact matchä¼˜å…ˆ,Possible matchæŠ˜å 

### é£é™©3: ä¸SkillåŠŸèƒ½é‡å 

**é£é™©**: `compound-knowledge-retriever` skillä¸ç°æœ‰skills (å¦‚`compound-docs`)èŒè´£æ··æ·†

**ç¼“è§£**:
- æ¸…æ™°åˆ’åˆ†èŒè´£:
  - `compound-docs`: **æ²‰æ·€** (å†™å…¥docs/solutions/)
  - `compound-knowledge-retriever`: **å¬å›** (è¯»å–+æ¨è)
- åœ¨SKILL.mdä¸­æ˜ç¡®è¯´æ˜äº’è¡¥å…³ç³»

### é£é™©4: è·¨é¡¹ç›®knowledgeä¸é€‚ç”¨

**é£é™©**: é¡¹ç›®Açš„solutionåœ¨é¡¹ç›®Bä¸work

**ç¼“è§£**:
- Solution YAML frontmatteråŒ…å«`project_context`å­—æ®µ
- å¬å›æ—¶ä¼˜å…ˆæœ¬é¡¹ç›®çš„solutions
- è·¨é¡¹ç›®solutionsæ ‡æ³¨"éœ€éªŒè¯é€‚ç”¨æ€§"

---

## ğŸ”Ÿ æ€»ç»“ä¸è¡ŒåŠ¨å»ºè®®

### æ ¸å¿ƒå‘ç°å›é¡¾

1. âœ… **Compoundæœºåˆ¶å·²ç»å¾ˆå¼ºå¤§**
   - 6ä¸ªå¹¶è¡Œå­ä»£ç†
   - ä¸¥æ ¼çš„YAML schemaéªŒè¯
   - ä¸‰çº§çŸ¥è¯†æ²‰æ·€è·¯å¾„ (L1æ–‡æ¡£ â†’ L2æ¨¡å¼ â†’ L3 Skill)

2. âš ï¸ **ä½†ç¼ºå°‘ä¸»åŠ¨å¬å›**
   - L1æ–‡æ¡£å±‚ (docs/solutions/) æ˜¯è¢«åŠ¨çŸ¥è¯†åº“
   - éœ€è¦"è®°å¾—å»æŸ¥" - ä¸Skillçš„"è‡ªåŠ¨å‘ç°"å½¢æˆå¯¹æ¯”
   - deepen-planæœ‰å¬å›é€»è¾‘,ä½†ä¸å¤Ÿè‡ªåŠ¨åŒ–å’Œæ³›åŒ–

3. ğŸ¯ **è§£å†³æ–¹æ¡ˆæ˜ç¡®**
   - **çŸ­æœŸ**: å¢å¼ºdeepen-plan + é›†æˆåˆ°plan/work
   - **ä¸­æœŸ**: åˆ›å»ºcompound-knowledge-retriever skill
   - **é•¿æœŸ**: AIä¸»åŠ¨å­¦ä¹ å’Œæ¨è

### ç«‹å³å¯æ‰§è¡Œçš„3ä¸ªAction Items

#### Action 1: åˆ›å»ºç´¢å¼•è„šæœ¬ (30åˆ†é’Ÿ)

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•
touch scripts/index_solutions.py
chmod +x scripts/index_solutions.py

# å®ç°ä¸Šæ–‡çš„index_solutions.pyé€»è¾‘
# æµ‹è¯•è¿è¡Œ
python3 scripts/index_solutions.py
# è¾“å‡º: .claude/artifacts/solutions-index.json
```

#### Action 2: å¢å¼º/workflow:plan (1å°æ—¶)

åœ¨ `plugins/compound-engineering/commands/workflows/plan.md` ä¸­:

```markdown
## Phase 1.5: Knowledge Retrieval (NEW)

After parallel research agents complete, before spec-flow-analyzer:

Task general-purpose: "
Search docs/solutions/ for relevant past solutions.

Technologies in this request: [extracted from user request]
Task type: [feature/bug/optimization]

Use the index at .claude/artifacts/solutions-index.json

Return top 3 relevant solutions with:
- Title and path
- Root cause
- Key insight
- Relevance score

Format for injection into plan's 'Known Pitfalls' section.
"
```

#### Action 3: æµ‹è¯•ä¸è¿­ä»£ (2å°æ—¶)

1. é€‰æ‹©ä¸€ä¸ªå·²æœ‰solution (å¦‚Redis caching)
2. è¿è¡Œ `/workflow:plan "Add caching to user API"`
3. éªŒè¯æ˜¯å¦å¬å›äº†ç›¸å…³solution
4. è°ƒæ•´relevanceç®—æ³•ç›´åˆ°å‡†ç¡®

### é•¿æœŸæ„¿æ™¯

**6ä¸ªæœˆåçš„ç†æƒ³çŠ¶æ€**:

```
ç”¨æˆ·: /workflow:plan "ä¼˜åŒ–é‚®ä»¶åŠ è½½é€Ÿåº¦"

Claude:
ğŸ“š æ£€æŸ¥è¿‡å¾€ç»éªŒ...
â†’ å‘ç°3ä¸ªç›¸å…³solutions:
  1. N+1æŸ¥è¯¢ä¼˜åŒ– (95%ç›¸å…³)
  2. Redisç¼“å­˜stampede (82%ç›¸å…³) 
  3. æ•°æ®åº“ç´¢å¼•ç¼ºå¤± (78%ç›¸å…³)

âœ“ å·²å°†learningsæ³¨å…¥plan

ğŸ¯ ç”Ÿæˆçš„planåŒ…å«:
- æœ€ä½³å®è·µ (from best-practices-researcher)
- æ¡†æ¶æ–‡æ¡£ (from framework-docs-researcher)
- **å·²çŸ¥å‘ç‚¹** (from compound-knowledge-retriever) â† NEW!

ç»§ç»­æ‰§è¡Œ? [Y/n]
```

**æ•ˆæœ**:
- âœ… KnowledgeåƒSkillä¸€æ ·è¢«è‡ªåŠ¨å¬å›
- âœ… æ¯æ¬¡è§£å†³é—®é¢˜å˜å¾—æ›´å¿« (çœŸæ­£çš„å¤åˆ©)
- âœ… å›¢é˜ŸçŸ¥è¯†æŒç»­ç§¯ç´¯å’Œå¤ç”¨
- âœ… æ–°æˆå‘˜å¿«é€Ÿè·å¾—è€æ‰‹çš„ç»éªŒ

---

## é™„å½•A: ç›¸å…³æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæœºåˆ¶æ–‡ä»¶

| æ–‡ä»¶ | ä½œç”¨ | å…³é”®å†…å®¹ |
|------|------|----------|
| `commands/workflows/compound.md` | Compoundå‘½ä»¤å®šä¹‰ | 6ä¸ªå¹¶è¡Œå­ä»£ç†,ä¸“ä¸šagentè°ƒç”¨ |
| `skills/compound-docs/SKILL.md` | Knowledgeæ²‰æ·€skill | 7æ­¥æµç¨‹,YAML validation |
| `skills/compound-docs/schema.yaml` | æ–‡æ¡£Schema | problem_type, componentç­‰æšä¸¾ |
| `commands/deepen-plan.md` | Planæ·±åŒ–å‘½ä»¤ | Step 3åŒ…å«learningså‘ç°é€»è¾‘ |
| `skills/skill-creator/SKILL.md` | Skillåˆ›å»ºæŒ‡å— | Progressive disclosureåŸåˆ™ |

### å»ºè®®æ–°å¢æ–‡ä»¶

| æ–‡ä»¶ | ä½œç”¨ | ä¼˜å…ˆçº§ |
|------|------|--------|
| `scripts/index_solutions.py` | æ„å»ºç´¢å¼• | P0 |
| `skills/compound-knowledge-retriever/SKILL.md` | å¬å›skill | P1 |
| `skills/compound-knowledge-retriever/scripts/retrieve_relevant.py` | æ£€ç´¢è„šæœ¬ | P1 |
| `.claude/artifacts/solutions-index.json` | Solutionç´¢å¼• | P0 |
| `agents/research/institutional-knowledge-researcher.md` | Knowledge agent (å¯é€‰) | P2 |

---

## é™„å½•B: å¯¹è¯å†å²ä¸­çš„çº¿ç´¢

ä»conversation 46515190 (`AI Knowledge Compounding Workflow`):
> ç”¨æˆ·ç›®æ ‡: conceptualize and implement a `/workflow:compound` command that automatically leverages a "skill-creator" to capture and store "knowledge pits" and best practices

**åˆ†æ**: ç”¨æˆ·å·²ç»åœ¨æ€è€ƒè¿™ä¸ªé—®é¢˜ - å¦‚ä½•è®©compoundçš„çŸ¥è¯†åƒskillä¸€æ ·å·¥ä½œã€‚

**æœ¬æ–‡æ¡£çš„å›ç­”**:
- âœ… `/workflow:compound` å·²å­˜åœ¨ä¸”åŠŸèƒ½å¼ºå¤§
- âœ… ç¼ºå°‘çš„æ˜¯"è‡ªåŠ¨leverage"éƒ¨åˆ† - å³å¬å›æœºåˆ¶
- âœ… æä¾›äº†3ä¸ªå¯è¡Œæ–¹æ¡ˆ,æ¨èskillåŒ–è·¯å¾„

---

*åˆ†æå®Œæˆæ—¶é—´: 2026-01-17*  
*åˆ†æè€…: Claude (Antigravity)*  
*åŸºäºé¡¹ç›®: compound-engineering-plugin*
